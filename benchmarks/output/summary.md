# LLM Incident Manager Benchmark Results

*Initial benchmark summary - run `llm-im-cli run` to generate results*

## Summary

This file will be populated with benchmark results when benchmarks are executed.

## Available Benchmark Targets

| Target ID | Description |
|-----------|-------------|
| alert-deduplication | Alert deduplication performance |
| alert-processing | Alert processing pipeline latency |
| escalation-workflow | Escalation workflow timing |
| oncall-routing | On-call routing rule evaluation |
| incident-correlation | Incident correlation throughput |
| circuit-breaker | Circuit breaker pattern overhead |
| metrics-collection | Prometheus metrics collection overhead |

## Running Benchmarks

```bash
# Run all benchmarks
llm-im-cli run

# Run specific target
llm-im-cli run --target alert-deduplication

# Output only JSON
llm-im-cli run --format json --quiet

# Custom output directory
llm-im-cli run --output /tmp/benchmark-results
```

## Benchmark Interface

This repository implements the canonical benchmark interface used across all 25 benchmark-target repositories:

```rust
// Entrypoint
pub async fn run_all_benchmarks() -> Vec<BenchmarkResult>;

// Result struct
pub struct BenchmarkResult {
    pub target_id: String,
    pub metrics: serde_json::Value,
    pub timestamp: DateTime<Utc>,
}

// Target trait
pub trait BenchTarget: Send + Sync {
    fn id(&self) -> String;
    async fn run(&self) -> BenchmarkResult;
}
```

---

*This report was generated by the LLM Incident Manager canonical benchmark system.*
